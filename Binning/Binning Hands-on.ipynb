{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Binning:\n",
    "___\n",
    "\n",
    "Let's understand Binning with an example: the famous [Titanic DataSet on Kaggle.](https://www.kaggle.com/c/titanic) <br>\n",
    "You don't have to download the dataset separately. Just clone the repo and try playing around with this notebook. <br>\n",
    "I have provided the train.csv file in the repo. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Titanic problem is a classic. So, I won't spoil it for you. <br> Let me just explain one small aspect of data cleaning that you would be doing on your own soon.\n",
    "#### Binning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Note that this tutorial is only for you to see a real application of Binning.<br>\n",
    "So, we won't care about the missing values or any other specific features of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Consider only the Age column. It contains the ages of all the passengers that had boarded the ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the ages array:  714\n",
      "[22.   38.   26.   35.   35.   54.    2.   27.   14.    4.   58.   20.\n",
      " 39.   14.   55.    2.   31.   35.   34.   15.   28.    8.   38.   19.\n",
      " 40.   66.   28.   42.   21.   18.   14.   40.   27.    3.   19.   18.\n",
      "  7.   21.   49.   29.   65.   21.   28.5   5.   11.   22.   38.   45.\n",
      "  4.   29.   19.   17.   26.   32.   16.   21.   26.   32.   25.    0.83\n",
      " 30.   22.   29.   28.   17.   33.   16.   23.   24.   29.   20.   46.\n",
      " 26.   59.   71.   23.   34.   34.   28.   21.   33.   37.   28.   21.\n",
      " 38.   47.   14.5  22.   20.   17.   21.   70.5  29.   24.    2.   21.\n",
      " 32.5  32.5  54.   12.   24.   45.   33.   20.   47.   29.   25.   23.\n",
      " 19.   37.   16.   24.   22.   24.   19.   18.   19.   27.    9.   36.5\n",
      " 42.   51.   22.   55.5  40.5  51.   16.   30.   44.   40.   26.   17.\n",
      "  1.    9.   45.   28.   61.    4.    1.   21.   56.   18.   50.   30.\n",
      " 36.    9.    1.    4.   45.   40.   36.   32.   19.   19.    3.   44.\n",
      " 58.   42.   24.   28.   34.   45.5  18.    2.   32.   26.   16.   40.\n",
      " 24.   35.   22.   30.   31.   27.   42.   32.   30.   16.   27.   51.\n",
      " 38.   22.   19.   20.5  18.   35.   29.   59.    5.   24.   44.    8.\n",
      " 19.   33.   29.   22.   30.   44.   25.   24.   37.   54.   29.   62.\n",
      " 30.   41.   29.   30.   35.   50.    3.   52.   40.   36.   16.   25.\n",
      " 58.   35.   25.   41.   37.   63.   45.    7.   35.   65.   28.   16.\n",
      " 19.   33.   30.   22.   42.   22.   26.   19.   36.   24.   24.   23.5\n",
      "  2.   50.   19.    0.92 17.   30.   30.   24.   18.   26.   28.   43.\n",
      " 26.   24.   54.   31.   40.   22.   27.   30.   22.   36.   61.   36.\n",
      " 31.   16.   45.5  38.   16.   29.   41.   45.   45.    2.   24.   28.\n",
      " 25.   36.   24.   40.    3.   42.   23.   15.   25.   28.   22.   38.\n",
      " 40.   29.   45.   35.   30.   60.   24.   25.   18.   19.   22.    3.\n",
      " 22.   27.   20.   19.   42.    1.   32.   35.   18.    1.   36.   17.\n",
      " 36.   21.   28.   23.   24.   22.   31.   46.   23.   28.   39.   26.\n",
      " 21.   28.   20.   34.   51.    3.   21.   33.   44.   34.   18.   30.\n",
      " 10.   21.   29.   28.   18.   28.   19.   32.   28.   42.   17.   50.\n",
      " 14.   21.   24.   64.   31.   45.   20.   25.   28.    4.   13.   34.\n",
      "  5.   52.   36.   30.   49.   29.   65.   50.   48.   34.   47.   48.\n",
      " 38.   56.    0.75 38.   33.   23.   22.   34.   29.   22.    2.    9.\n",
      " 50.   63.   25.   35.   58.   30.    9.   21.   55.   71.   21.   54.\n",
      " 25.   24.   17.   21.   37.   16.   18.   33.   28.   26.   29.   36.\n",
      " 54.   24.   47.   34.   36.   32.   30.   22.   44.   40.5  50.   39.\n",
      " 23.    2.   17.   30.    7.   45.   30.   22.   36.    9.   11.   32.\n",
      " 50.   64.   19.   33.    8.   17.   27.   22.   22.   62.   48.   39.\n",
      " 36.   40.   28.   24.   19.   29.   32.   62.   53.   36.   16.   19.\n",
      " 34.   39.   32.   25.   39.   54.   36.   18.   47.   60.   22.   35.\n",
      " 52.   47.   37.   36.   49.   49.   24.   44.   35.   36.   30.   27.\n",
      " 22.   40.   39.   35.   24.   34.   26.    4.   26.   27.   42.   20.\n",
      " 21.   21.   61.   57.   21.   26.   80.   51.   32.    9.   28.   32.\n",
      " 31.   41.   20.   24.    2.    0.75 48.   19.   56.   23.   18.   21.\n",
      " 18.   24.   32.   23.   58.   50.   40.   47.   36.   20.   32.   25.\n",
      " 43.   40.   31.   70.   31.   18.   24.5  18.   43.   36.   27.   20.\n",
      " 14.   60.   25.   14.   19.   18.   15.   31.    4.   25.   60.   52.\n",
      " 44.   49.   42.   18.   35.   18.   25.   26.   39.   45.   42.   22.\n",
      " 24.   48.   29.   52.   19.   38.   27.   33.    6.   17.   34.   50.\n",
      " 27.   20.   30.   25.   25.   29.   11.   23.   23.   28.5  48.   35.\n",
      " 36.   21.   24.   31.   70.   16.   30.   19.   31.    4.    6.   33.\n",
      " 23.   48.    0.67 28.   18.   34.   33.   41.   20.   36.   16.   51.\n",
      " 30.5  32.   24.   48.   57.   54.   18.    5.   43.   13.   17.   29.\n",
      " 25.   25.   18.    8.    1.   46.   16.   25.   39.   49.   31.   30.\n",
      " 30.   34.   31.   11.    0.42 27.   31.   39.   18.   39.   33.   26.\n",
      " 39.   35.    6.   30.5  23.   31.   43.   10.   52.   27.   38.   27.\n",
      "  2.    1.   62.   15.    0.83 23.   18.   39.   21.   32.   20.   16.\n",
      " 30.   34.5  17.   42.   35.   28.    4.   74.    9.   16.   44.   18.\n",
      " 45.   51.   24.   41.   21.   48.   24.   42.   27.   31.    4.   26.\n",
      " 47.   33.   47.   28.   15.   20.   19.   56.   25.   33.   22.   28.\n",
      " 25.   39.   27.   19.   26.   32.  ]\n"
     ]
    }
   ],
   "source": [
    "ages = df[\"Age\"].dropna()\n",
    "ages = np.array(ages)\n",
    "print(\"Length of the ages array: \", len(ages))\n",
    "print(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put these age entries into different bins, we must make those bins first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make sure you explore each new function that you encounter by pressing \"**Shift**\" + \"**Tab**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.  10.  20.  30.  40.  50.  60.  70.  80.  90. 100.]\n"
     ]
    }
   ],
   "source": [
    "bins = np.linspace(0,100,11)\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are going to be the boundaries for all the bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**np.digitize()** is a function that can be used to segregate the data into the bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data points:\n",
      " [22. 38. 26. 35. 35.]\n",
      "\n",
      "Bin membership for data points:\n",
      " [3 4 3 4 4]\n"
     ]
    }
   ],
   "source": [
    "binned_ages = np.digitize(ages, bins, right = False)\n",
    "print(\"\\nData points:\\n\", ages[:5])\n",
    "print(\"\\nBin membership for data points:\\n\", binned_ages[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 3 4 4 6 1 3 2 1 6 3 4 2 6 1 4 4 4 2 3 1 4 2 5 7 3 5 3 2 2 5 3 1 2 2 1\n",
      " 3 5 3 7 3 3 1 2 3 4 5 1 3 2 2 3 4 2 3 3 4 3 1 4 3 3 3 2 4 2 3 3 3 3 5 3 6\n",
      " 8 3 4 4 3 3 4 4 3 3 4 5 2 3 3 2 3 8 3 3 1 3 4 4 6 2 3 5 4 3 5 3 3 3 2 4 2\n",
      " 3 3 3 2 2 2 3 1 4 5 6 3 6 5 6 2 4 5 5 3 2 1 1 5 3 7 1 1 3 6 2 6 4 4 1 1 1\n",
      " 5 5 4 4 2 2 1 5 6 5 3 3 4 5 2 1 4 3 2 5 3 4 3 4 4 3 5 4 4 2 3 6 4 3 2 3 2\n",
      " 4 3 6 1 3 5 1 2 4 3 3 4 5 3 3 4 6 3 7 4 5 3 4 4 6 1 6 5 4 2 3 6 4 3 5 4 7\n",
      " 5 1 4 7 3 2 2 4 4 3 5 3 3 2 4 3 3 3 1 6 2 1 2 4 4 3 2 3 3 5 3 3 6 4 5 3 3\n",
      " 4 3 4 7 4 4 2 5 4 2 3 5 5 5 1 3 3 3 4 3 5 1 5 3 2 3 3 3 4 5 3 5 4 4 7 3 3\n",
      " 2 2 3 1 3 3 3 2 5 1 4 4 2 1 4 2 4 3 3 3 3 3 4 5 3 3 4 3 3 3 3 4 6 1 3 4 5\n",
      " 4 2 4 2 3 3 3 2 3 2 4 3 5 2 6 2 3 3 7 4 5 3 3 3 1 2 4 1 6 4 4 5 3 7 6 5 4\n",
      " 5 5 4 6 1 4 4 3 3 4 3 3 1 1 6 7 3 4 6 4 1 3 6 8 3 6 3 3 2 3 4 2 2 4 3 3 3\n",
      " 4 6 3 5 4 4 4 4 3 5 5 6 4 3 1 2 4 1 5 4 3 4 1 2 4 6 7 2 4 1 2 3 3 3 7 5 4\n",
      " 4 5 3 3 2 3 4 7 6 4 2 2 4 4 4 3 4 6 4 2 5 7 3 4 6 5 4 4 5 5 3 5 4 4 4 3 3\n",
      " 5 4 4 3 4 3 1 3 3 5 3 3 3 7 6 3 3 9 6 4 1 3 4 4 5 3 3 1 1 5 2 6 3 2 3 2 3\n",
      " 4 3 6 6 5 5 4 3 4 3 5 5 4 8 4 2 3 2 5 4 3 3 2 7 3 2 2 2 2 4 1 3 7 6 5 5 5\n",
      " 2 4 2 3 3 4 5 5 3 3 5 3 6 2 4 3 4 1 2 4 6 3 3 4 3 3 3 2 3 3 3 5 4 4 3 3 4\n",
      " 8 2 4 2 4 1 1 4 3 5 1 3 2 4 4 5 3 4 2 6 4 4 3 5 6 6 2 1 5 2 2 3 3 3 2 1 1\n",
      " 5 2 3 4 5 4 4 4 4 4 2 1 3 4 4 2 4 4 3 4 4 1 4 3 4 5 2 6 3 4 3 1 1 7 2 1 3\n",
      " 2 4 3 4 3 2 4 4 2 5 4 3 1 8 1 2 5 2 5 6 3 5 3 5 3 5 3 4 1 3 5 4 5 3 2 3 2\n",
      " 6 3 4 3 3 3 4 3 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(binned_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the age data is **much more useful** for the classification problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
